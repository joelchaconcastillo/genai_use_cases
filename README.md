# üß† GenAI Cookbook

A practical, notebook-based collection of **real-world Generative AI patterns and systems**.  
This repository contains **self-contained Jupyter notebooks** that demonstrate how to design, build, and orchestrate modern GenAI applications ‚Äî from RAG pipelines to multi-agent and multimodal systems.
---

## üéØ Goals

- Provide clear, runnable examples of common Generative AI capabilities
- Focus on reusable **design patterns**, not just libraries or tools
- Progress from fundamentals to advanced orchestration
- Serve as a long-term **reference cookbook** for GenAI system builders

---

## üóÇ Repository Structure

The repository is organized by **capability first**, then **pattern**, and finally **tool-specific implementations**.


genai-cookbook/
‚îú‚îÄ notebooks/
‚îÇ ‚îú‚îÄ 01-fundamentals/
‚îÇ ‚îú‚îÄ 02-embeddings/
‚îÇ ‚îú‚îÄ 03-retrieval-and-search/
‚îÇ ‚îú‚îÄ 04-data-reasoning/
 ‚îÇ ‚îú‚îÄ 05-multimodal/
‚îÇ ‚îú‚îÄ 06-conversational-systems/
‚îÇ ‚îú‚îÄ 07-agents/
‚îÇ ‚îú‚îÄ 08-orchestration-patterns/
‚îÇ ‚îú‚îÄ 09-langgraph-patterns/
‚îÇ ‚îú‚îÄ 10-end-to-end-systems/
‚îú‚îÄ data/
‚îú‚îÄ utils/
‚îî‚îÄ README.md


---

## üìö Topics Covered

### 1Ô∏è‚É£ Fundamentals
Core concepts required for all GenAI systems.

- Prompt engineering
- Model parameters & determinism
- Prompt templates and system prompts

---

### 2Ô∏è‚É£ Embeddings & Vector Search
Foundations for semantic retrieval.

- Embedding generation
- Chunking strategies
- Vector similarity search

---

### 3Ô∏è‚É£ Retrieval & Search Systems
Getting the right information into the model.

- Retrieval-Augmented Generation (RAG)
- Recommender systems
- Web search with Tavily
- Hybrid retrieval strategies

---

### 4Ô∏è‚É£ Data Reasoning & Querying
LLMs reasoning over structured data.

- DataFrame analyzers
- Natural language to SQL
- Query generation & execution

---

### 5Ô∏è‚É£ Multimodal AI
Beyond text-only workflows.

- Multimodal LLMs
- Image caption generation
- Text-to-Speech (TTS)
- Speech-to-Text (STT)

---

### 6Ô∏è‚É£ Conversational & UI Systems
User-facing AI applications.

- AI-powered dashboards
- Conversational systems
- BeeAI-based AI conversations

---

### 7Ô∏è‚É£ Agent Systems
Autonomous and tool-using LLMs.

- Single-agent workflows
- Multi-agent systems
- CrewAI fundamentals
- Custom CrewAI tools and classes

---

### 8Ô∏è‚É£ Orchestration Patterns
Controlling execution flow and reasoning.

- Orchestrator pattern
- Evaluator‚ÄìOptimizer pattern
- Tool selection and retry strategies

---

### 9Ô∏è‚É£ LangGraph Patterns
Explicit control-flow graphs for LLM systems.

- Sequence pattern
- Routing pattern
- Parallelization pattern

---

### üîü End-to-End Systems
Full systems combining multiple capabilities.

- RAG + agents + orchestration
- Multimodal assistants
- Data-aware AI dashboards

---

## üß© Notebook Metadata Convention

Each notebook starts with a short header:

```md
**Capability:** Retrieval & Search  
**Pattern:** Orchestrator / Routing  
**Tools:** LangGraph, OpenAI, FAISS

```

---

## üõ† Hands-on: How to use this repo (practical workflow)

This repository is organized as a cookbook of patterns. To turn these patterns into functional source code and portfolio pieces, follow this practical workflow:

- **1. Read the Cheatsheet:** start with `CHEATSHEET.md` for quick, runnable examples and setup instructions.
- **2. Pick a priority use case:** choose one of the topics below that maps to your contractor duties (e.g., RAG demo, embedding pipeline, fine-tuning classifier).
- **3. Create an example folder:** under a directory such as `examples/<topic>-<short-name>/` include:
  - `notebook.ipynb` ‚Äî an end-to-end demo and narrative.
  - `app.py` or `service/` ‚Äî minimal API server (FastAPI) to expose the model.
  - `requirements.txt` ‚Äî pinned deps for reproducibility.
  - `README.md` ‚Äî how to run, dataset pointers, and expected outputs.
  - `tests/` ‚Äî small unit tests (sanity checks and smoke tests).
- **4. Iteratively improve:** add evaluation, logging, privacy notes, and CI workflow.

**Centralized configuration & LLM management**

This repo uses a small centralized configuration pattern to make examples portable and reproducible:

- Store named LLM profiles in `configs/llm_profiles.yaml` (example included).
- Put secrets in environment variables and an optional local `.env` (see `.env.example`).
- Use `utils/llm_manager.py` to load profiles and get a small client with `generate(prompt)`.

This approach keeps secrets out of code, lets examples pick named profiles, and makes it easy to switch providers.

## üéØ Prioritized examples (aligns to your Statement of Work)

- **RAG demo (High priority):** embeddings -> FAISS -> retriever -> LLM summarization. Good for business-aligned extraction tasks.
- **Embedding pipeline (High priority):** dataset chunking, embedding generation, index storage/encryption.
- **Fine-tuning prototype (Medium):** small-scope fine-tune (classification or summarization) with evaluation metrics and reproducible training script.
- **Serving & Integrations (Medium):** FastAPI service + minimal frontend or a demo curl workflow.
- **Data reasoning / SQL assistant (Medium):** natural-language-to-SQL with safety checks and execution sandboxing.
- **Multimodal prototype (Low/Optional):** image captioning or TTS demo.

## ‚úÖ Repo conventions for example folders

- Use `examples/<topic>-<short-name>/` as the canonical place for runnable code.
- Each example MUST include `README.md` with these headings: Purpose, Setup, Run, Expected output, Notes on Privacy & Limitations.
- Keep scripts idempotent and small (one CLI per script).
- Add a `requirements.txt` and, when possible, `environment.yml` or `pyproject.toml` for reproducible installs.

## üîê Data privacy & security (baseline checklist)

- Avoid including raw PII in repo assets.
- Document any sensitive data requirements in the example `README.md` and suggest synthetic datasets for demos.
- Provide instructions for storing API keys in environment variables (never hardcode secrets).

---

## GenAI Hands-on Cheatsheet

A concise, practical cheatsheet with runnable code snippets to help you prepare for GenAI engineering tasks listed in your Statement of Work.

**Setup**
- Create a virtual environment and install dependencies:

```bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

**Quick: Model inference (Hugging Face Transformers)**

```python
from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM
import torch

model_name = "gpt2"
device = 0 if torch.cuda.is_available() else -1

pipe = pipeline("text-generation", model=model_name, device=device)
resp = pipe("Translate to Spanish: How are you?", max_new_tokens=40)
print(resp[0]["generated_text"]) 
```

Notes: replace `gpt2` with a local or Hugging Face Hub model appropriate for your task.

**Fine-tuning (Hugging Face Trainer) ‚Äî minimal text classification**

```python
from datasets import load_dataset
from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer

dataset = load_dataset("imdb")
tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased")

def preprocess(batch):
    return tokenizer(batch["text"], truncation=True, padding="max_length", max_length=128)

dataset = dataset.map(preprocess, batched=True)
model = AutoModelForSequenceClassification.from_pretrained("distilbert-base-uncased", num_labels=2)

training_args = TrainingArguments(
    output_dir="./out", num_train_epochs=1, per_device_train_batch_size=8, logging_steps=50
)

trainer = Trainer(model=model, args=training_args, train_dataset=dataset["train"].select(range(2000)), eval_dataset=dataset["test"].select(range(500)))
trainer.train()
```

**Embeddings + FAISS (semantic retrieval)**

```python
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np

model = SentenceTransformer('all-MiniLM-L6-v2')
docs = ["Hello world","Generative AI patterns","How to fine-tune models"]
embs = model.encode(docs, convert_to_numpy=True)

dim = embs.shape[1]
index = faiss.IndexFlatL2(dim)
index.add(embs)

q = model.encode(["fine-tuning steps"], convert_to_numpy=True)
distances, idxs = index.search(q, k=2)
print(idxs, distances)
```

**RAG (retrieval-augmented generation) ‚Äî sketch with LangChain**

```python
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.llms import OpenAI

# Prepare embeddings and index (example with OpenAI)
emb = OpenAIEmbeddings()
# texts = [ ... ]
# embeddings = emb.embed_documents(texts)
# faiss_index = FAISS.from_documents(texts, emb)

# Use RetrievalQA
qa = RetrievalQA.from_chain_type(llm=OpenAI(model_name="gpt-4o-mini"), chain_type="stuff", retriever=faiss_index.as_retriever())
print(qa.run("Summarize the approach for retrieval-augmented generation."))
```

Replace `OpenAI` usage with your preferred LLM provider and set API keys through environment variables.

**Serving a model: FastAPI example**

```python
from fastapi import FastAPI
from pydantic import BaseModel
from transformers import pipeline

app = FastAPI()
generator = pipeline('text-generation', model='gpt2')

class Req(BaseModel):
    prompt: str

@app.post('/generate')
def generate(req: Req):
    out = generator(req.prompt, max_new_tokens=80)
    return {"text": out[0]['generated_text']}

# Run: uvicorn app:app --reload --port 8000
```

**Evaluation snippets**

```python
from sklearn.metrics import accuracy_score, f1_score
# Binary classification
y_true = [0,1,1,0]
y_pred = [0,1,0,0]
print('Accuracy', accuracy_score(y_true,y_pred))
print('F1', f1_score(y_true,y_pred))
```

**Testing a small function**

```python
def normalize(s):
    return s.strip().lower()

def test_normalize():
    assert normalize(' Hello ') == 'hello'

if __name__ == '__main__':
    test_normalize(); print('ok')
```

**Data Privacy & Security Checklist**
- Minimize and anonymize PII in training data.
- Prefer embeddings + retrieval over sending raw docs to LLM for sensitive info.
- Use encryption-at-rest for indexes and storage.
- Apply access controls to API keys and rotate them regularly.
- Keep audit logs of data access and model outputs when required.

**Useful commands**
- Format Python: `python -m pip install black && black .`
- Run FastAPI server: `uvicorn app:app --reload --port 8000`

---

## ‚úÖ Repo conventions for example folders

- Use `examples/<topic>-<short-name>/` as the canonical place for runnable code.
- Each example MUST include `README.md` with these headings: Purpose, Setup, Run, Expected output, Notes on Privacy & Limitations.
- Keep scripts idempotent and small (one CLI per script).
- Add a `requirements.txt` and, when possible, `environment.yml` or `pyproject.toml` for reproducible installs.

## üîê Data privacy & security (baseline checklist)

- Avoid including raw PII in repo assets.
- Document any sensitive data requirements in the example `README.md` and suggest synthetic datasets for demos.
- Provide instructions for storing API keys in environment variables (never hardcode secrets).

## üß≠ Next steps I can do for you

- Scaffold an `examples/rag-demo/` with notebook, scripts, and tests.
- Create a runnable FastAPI service with Dockerfile and simple CI workflow that runs smoke tests.
- Expand `CHEATSHEET.md` into a notebook and small example repo for one chosen topic.

Tell me which next step you want prioritized and I will scaffold it (RAG demo, Fine-tuning prototype, or FastAPI service).



## üìö Topics Covered

### 1Ô∏è‚É£ Fundamentals
Core concepts required for all GenAI systems.

- Prompt engineering
- Model parameters & determinism
- Prompt templates and system prompts

---

### 2Ô∏è‚É£ Embeddings & Vector Search
Foundations for semantic retrieval.

- Embedding generation
- Chunking strategies
- Vector similarity search

---

### 3Ô∏è‚É£ Retrieval & Search Systems
Getting the right information into the model.

- Retrieval-Augmented Generation (RAG)
- Recommender systems
- Web search with Tavily
- Hybrid retrieval strategies

---

### 4Ô∏è‚É£ Data Reasoning & Querying
LLMs reasoning over structured data.

- DataFrame analyzers
- Natural language to SQL
- Query generation & execution

---

### 5Ô∏è‚É£ Multimodal AI
Beyond text-only workflows.

- Multimodal LLMs
- Image caption generation
- Text-to-Speech (TTS)
- Speech-to-Text (STT)

---

### 6Ô∏è‚É£ Conversational & UI Systems
User-facing AI applications.

- AI-powered dashboards
- Conversational systems
- BeeAI-based AI conversations

---

### 7Ô∏è‚É£ Agent Systems
Autonomous and tool-using LLMs.

- Single-agent workflows
- Multi-agent systems
- CrewAI fundamentals
- Custom CrewAI tools and classes

---

### 8Ô∏è‚É£ Orchestration Patterns
Controlling execution flow and reasoning.

- Orchestrator pattern
- Evaluator‚ÄìOptimizer pattern
- Tool selection and retry strategies

---

### 9Ô∏è‚É£ LangGraph Patterns
Explicit control-flow graphs for LLM systems.

- Sequence pattern
- Routing pattern
- Parallelization pattern

---

### üîü End-to-End Systems
Full systems combining multiple capabilities.

- RAG + agents + orchestration
- Multimodal assistants
- Data-aware AI dashboards

---

## üß© Notebook Metadata Convention

Each notebook starts with a short header:

```md
**Capability:** Retrieval & Search  
**Pattern:** Orchestrator / Routing  
**Tools:** LangGraph, OpenAI, FAISS

